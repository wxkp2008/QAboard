{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from os import listdir\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold #交叉验证\n",
    "from sklearn.model_selection import GridSearchCV  #通过网络方式来获取参数\n",
    "from sklearn.model_selection import train_test_split #将数据集分开成训练集和测试集\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2vector(filename):\n",
    "    returnVect = zeros((1, 1024))\n",
    "    fr = open(filename)\n",
    "    for i in range(32):\n",
    "        lineStr = fr.readline()\n",
    "        for j in range(32):\n",
    "            returnVect[0, 32 * i + j] = int(lineStr[j])\n",
    "    return returnVect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handwritingClassTest():\n",
    "    # 1. 导入训练数据\n",
    "    hwLabels = []\n",
    "    trainingFileList = listdir('trainingDigits')  # load the training set\n",
    "    m = len(trainingFileList)\n",
    "    trainingMat = zeros((m, 1024))\n",
    "    # hwLabels存储0～9对应的index位置， trainingMat存放的每个位置对应的图片向量\n",
    "    for i in range(m):\n",
    "        fileNameStr = trainingFileList[i]\n",
    "        fileStr = fileNameStr.split('.')[0]  # take off .txt\n",
    "        classNumStr = int(fileStr.split('_')[0])\n",
    "        hwLabels.append(classNumStr)\n",
    "        # 将 32*32的矩阵->1*1024的矩阵\n",
    "        trainingMat[i, :] = img2vector('trainingDigits/%s' % fileNameStr)    \n",
    "        \n",
    "    print(trainingMat.shape,len(hwLabels))   \n",
    "       \n",
    "    '''\n",
    "    #K折交叉验证\n",
    "    seed = 7 #重现随机生成的训练\n",
    "    test_size = 0.1 #80%测试，20%训练\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(trainingMat, hwLabels, \n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=seed)\n",
    "    #KNN = KNeighborsClassifier()  \n",
    "    MNB = MultinomialNB()\n",
    "    \n",
    "    #param_grid = {'n_neighbors':range(1,15,2)} \n",
    "    param_grid = {'alpha':[i/100.0 for i in range(200)] }\n",
    "    \n",
    "    kflod = StratifiedKFold(n_splits = 10, shuffle = True,random_state = seed)#将训练/测试数据集划分10个互斥子集， \n",
    "    \n",
    "    #grid_search = GridSearchCV(KNN,param_grid,n_jobs = -1,cv = kflod)\n",
    "    \n",
    "    grid_search = GridSearchCV(MNB,param_grid,n_jobs = -1,cv = kflod)\n",
    "    \n",
    "    grid_result = grid_search.fit(X_train, Y_train) #运行网格搜索\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_,grid_search.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean,param in zip(means,params):\n",
    "        print(\"%f  with:   %r\" % (mean,param))\n",
    "    '''\n",
    "    #K折交叉验证得最优K值为3：\n",
    "    #KNN = KNeighborsClassifier(3)\n",
    "    #KNN.fit(trainingMat,hwLabels)\n",
    "    \n",
    "    #Kz折交叉验证得最优alpha值为1.41-1.67：\n",
    "    MNB = MultinomialNB(alpha=1.5)\n",
    "    MNB.fit(trainingMat,hwLabels)\n",
    "    \n",
    "    \n",
    "    # 2. 导入测试数据\n",
    "    testFileList = listdir('testDigits')  # iterate through the test set\n",
    "    errorCount = 0.0\n",
    "    mTest = len(testFileList)\n",
    "    for i in range(mTest):\n",
    "        fileNameStr = testFileList[i]\n",
    "        fileStr = fileNameStr.split('.')[0]  # take off .txt\n",
    "        classNumStr = int(fileStr.split('_')[0])\n",
    "        vectorUnderTest = img2vector('testDigits/%s' % fileNameStr)\n",
    "        \n",
    "          \n",
    "        #获得测试结果\n",
    "        '''\n",
    "        classifierResult = KNN.predict(vectorUnderTest)\n",
    "        #print(\"the classifier came back with: %d, the real answer is: %d\" % (classifierResult, classNumStr))\n",
    "        if (classifierResult != classNumStr): \n",
    "            errorCount += 1.0\n",
    "        '''   \n",
    "\n",
    "        classifierResult = MNB.predict(vectorUnderTest)\n",
    "        if (classifierResult != classNumStr): \n",
    "            errorCount += 1.0                    \n",
    "        \n",
    "    print(\"\\nthe total number of errors is: %d\" % errorCount)\n",
    "    print(\"\\nthe total error rate is: %f\" % (errorCount / float(mTest)))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1934, 1024) 1934\n",
      "\n",
      "the total number of errors is: 72\n",
      "\n",
      "the total error rate is: 0.076110\n"
     ]
    }
   ],
   "source": [
    "handwritingClassTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN和NB的比较：\n",
    "### 从分类表现来看，KNN准确率高，速度较慢；MNB准确率低，速度快。\n",
    "### 超参调优方面看，KNN超参依赖样本，NB的超参只关于本身。有啥好处现在也说不清楚……"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2] *",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
